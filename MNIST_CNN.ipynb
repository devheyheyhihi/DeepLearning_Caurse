{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"MNIST_CNN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"udKJ2U9ythy-","colab_type":"code","outputId":"f86de5ed-5b78-42d4-f909-fdb7f47900a1","executionInfo":{"status":"ok","timestamp":1578012152673,"user_tz":-540,"elapsed":2815,"user":{"displayName":"h i","photoUrl":"","userId":"10569797021359250176"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Tqhth_QjthzL","colab_type":"code","outputId":"8aeb849d-d6bf-4831-db10-8c2fc81ae8e6","executionInfo":{"status":"ok","timestamp":1578012156090,"user_tz":-540,"elapsed":6221,"user":{"displayName":"h i","photoUrl":"","userId":"10569797021359250176"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)  \n","#tmp폴더는 끄면 사라짐 유사램"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-2-d7353bb7b51b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /tmp/data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /tmp/data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g1JHUoTIthzT","colab_type":"code","colab":{}},"source":["num_epochs=10000\n","batch_size=100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VnsGm1pthzb","colab_type":"code","colab":{}},"source":["#CNN모델을 함수로 생성\n","def build_CNN_classifier(x):\n","    x_image = tf.reshape(x, [-1,28,28,1])\n","    \n","    # 1st convlution layer\n","    # kernel 5x5 32filter\n","    #28x28x1 --> 28x28x32  zeropadding\n","    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32], stddev=5e-2))\n","    b_conv1 = tf.Variable(tf.constant (0.1, shape=[32]))\n","                                    #2차원 컨벌루션이기 때문에 2d\n","    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image,W_conv1,strides=[1,1,1,1]\n","                                      ,padding=\"SAME\") + b_conv1) \n","                                        #입력과 출력 크기 같게 해줌\n","    \n","    #1st pooling layer\n","    #max_pooling 1/2 downsample\n","    #28x28x32  --> 14x14x32           커널 사이즈\n","    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,2,2,1],strides=[1,2,2,1], \n","                             padding='SAME')\n","        \n","    # 2nd convlution layer\n","    # kernel 5x5 64filter\n","    #14x14x32 --> 14x14x64    \n","    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64], stddev=5e-2))\n","    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n","    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1,W_conv2,strides=[1,1,1,1],\n","                                      padding=\"SAME\") + b_conv2) \n","    \n","    #2nd pooling layer\n","    #max_pooling 1/2 downsample\n","    #28x28x32  --> 7x7x32  (풀링은 채널개수 변화 없음)\n","    h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,2,2,1],strides=[1,2,2,1], \n","                             padding='SAME')\n","    \n","    #Fully connected Layer\n","    #7x7크기를 가진 64개의 activation map을 1024개의 Feature로 변환한다.\n","    #7x7x64=3136 -> 1024                                         률분산률\n","    W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64, 1024], stddev=5e-2))\n","    b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]))\n","    h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*64])\n","    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n","    \n","    #output Layer\n","    W_output = tf.Variable(tf.truncated_normal(shape=[1024, 10], stddev=5e-2))\n","    b_output = tf.Variable(tf.constant(0.1, shape=[10]))\n","    logits = tf.matmul(h_fc1, W_output)+b_output\n","    y_pred = tf.nn.softmax(logits)\n","    ㅡ\n","    return y_pred, logits"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV1pacRpthzi","colab_type":"code","colab":{}},"source":["x = tf.placeholder(tf.float32, shape=[None, 784])\n","y = tf.placeholder(tf.float32, shape=[None, 10])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMT6TXmQthzo","colab_type":"code","colab":{}},"source":["y_pred, logits = build_CNN_classifier(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbOdi5UOthzt","colab_type":"code","colab":{}},"source":["loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MM2IQsdthzy","colab_type":"code","colab":{}},"source":["train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_EKVK5ROthz2","colab_type":"code","colab":{}},"source":["correct_prediction = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"79KcLxWNthz8","colab_type":"code","colab":{}},"source":["accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Knc9hUCsth0B","colab_type":"code","outputId":"794a7812-85bc-4b37-fa67-01aa31fad66c","executionInfo":{"status":"ok","timestamp":1578012213383,"user_tz":-540,"elapsed":63455,"user":{"displayName":"h i","photoUrl":"","userId":"10569797021359250176"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    \n","    for i in range(num_epochs):\n","        batch_x, batch_y = mnist.train.next_batch(batch_size)\n","        if i % 100 == 0:\n","            batch_vx,batch_vy=mnist.validation.next_batch(batch_size)\n","            train_accuracy = accuracy.eval(feed_dict={x:batch_vx, y:batch_vy})\n","            print(\"Epoch:%d, train_accuracy: %f\" %(i,train_accuracy))\n","        sess.run([train_step], feed_dict={x:batch_x, y:batch_y})\n","        \n","    print(\"test accuracy:%f\" %accuracy.eval(feed_dict={x:mnist.test.images,\n","                                                      y:mnist.test.labels}))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch:0, train_accuracy: 0.060000\n","Epoch:100, train_accuracy: 0.850000\n","Epoch:200, train_accuracy: 0.920000\n","Epoch:300, train_accuracy: 0.930000\n","Epoch:400, train_accuracy: 0.950000\n","Epoch:500, train_accuracy: 0.970000\n","Epoch:600, train_accuracy: 0.960000\n","Epoch:700, train_accuracy: 0.970000\n","Epoch:800, train_accuracy: 0.990000\n","Epoch:900, train_accuracy: 0.960000\n","Epoch:1000, train_accuracy: 0.970000\n","Epoch:1100, train_accuracy: 0.990000\n","Epoch:1200, train_accuracy: 0.970000\n","Epoch:1300, train_accuracy: 0.960000\n","Epoch:1400, train_accuracy: 0.980000\n","Epoch:1500, train_accuracy: 0.980000\n","Epoch:1600, train_accuracy: 0.960000\n","Epoch:1700, train_accuracy: 0.990000\n","Epoch:1800, train_accuracy: 0.990000\n","Epoch:1900, train_accuracy: 0.970000\n","Epoch:2000, train_accuracy: 0.990000\n","Epoch:2100, train_accuracy: 1.000000\n","Epoch:2200, train_accuracy: 0.960000\n","Epoch:2300, train_accuracy: 0.980000\n","Epoch:2400, train_accuracy: 0.980000\n","Epoch:2500, train_accuracy: 0.990000\n","Epoch:2600, train_accuracy: 1.000000\n","Epoch:2700, train_accuracy: 0.990000\n","Epoch:2800, train_accuracy: 0.990000\n","Epoch:2900, train_accuracy: 0.990000\n","Epoch:3000, train_accuracy: 0.980000\n","Epoch:3100, train_accuracy: 1.000000\n","Epoch:3200, train_accuracy: 0.980000\n","Epoch:3300, train_accuracy: 0.970000\n","Epoch:3400, train_accuracy: 0.990000\n","Epoch:3500, train_accuracy: 0.990000\n","Epoch:3600, train_accuracy: 0.970000\n","Epoch:3700, train_accuracy: 0.980000\n","Epoch:3800, train_accuracy: 1.000000\n","Epoch:3900, train_accuracy: 0.990000\n","Epoch:4000, train_accuracy: 0.990000\n","Epoch:4100, train_accuracy: 1.000000\n","Epoch:4200, train_accuracy: 0.990000\n","Epoch:4300, train_accuracy: 1.000000\n","Epoch:4400, train_accuracy: 0.990000\n","Epoch:4500, train_accuracy: 0.980000\n","Epoch:4600, train_accuracy: 1.000000\n","Epoch:4700, train_accuracy: 0.980000\n","Epoch:4800, train_accuracy: 0.980000\n","Epoch:4900, train_accuracy: 0.980000\n","Epoch:5000, train_accuracy: 1.000000\n","Epoch:5100, train_accuracy: 1.000000\n","Epoch:5200, train_accuracy: 1.000000\n","Epoch:5300, train_accuracy: 0.970000\n","Epoch:5400, train_accuracy: 0.990000\n","Epoch:5500, train_accuracy: 0.980000\n","Epoch:5600, train_accuracy: 1.000000\n","Epoch:5700, train_accuracy: 1.000000\n","Epoch:5800, train_accuracy: 0.990000\n","Epoch:5900, train_accuracy: 1.000000\n","Epoch:6000, train_accuracy: 1.000000\n","Epoch:6100, train_accuracy: 0.990000\n","Epoch:6200, train_accuracy: 0.990000\n","Epoch:6300, train_accuracy: 1.000000\n","Epoch:6400, train_accuracy: 0.990000\n","Epoch:6500, train_accuracy: 0.980000\n","Epoch:6600, train_accuracy: 1.000000\n","Epoch:6700, train_accuracy: 0.970000\n","Epoch:6800, train_accuracy: 0.970000\n","Epoch:6900, train_accuracy: 0.970000\n","Epoch:7000, train_accuracy: 1.000000\n","Epoch:7100, train_accuracy: 1.000000\n","Epoch:7200, train_accuracy: 0.970000\n","Epoch:7300, train_accuracy: 0.990000\n","Epoch:7400, train_accuracy: 0.980000\n","Epoch:7500, train_accuracy: 1.000000\n","Epoch:7600, train_accuracy: 0.970000\n","Epoch:7700, train_accuracy: 1.000000\n","Epoch:7800, train_accuracy: 0.990000\n","Epoch:7900, train_accuracy: 1.000000\n","Epoch:8000, train_accuracy: 0.990000\n","Epoch:8100, train_accuracy: 1.000000\n","Epoch:8200, train_accuracy: 0.990000\n","Epoch:8300, train_accuracy: 0.980000\n","Epoch:8400, train_accuracy: 1.000000\n","Epoch:8500, train_accuracy: 1.000000\n","Epoch:8600, train_accuracy: 0.990000\n","Epoch:8700, train_accuracy: 1.000000\n","Epoch:8800, train_accuracy: 0.990000\n","Epoch:8900, train_accuracy: 1.000000\n","Epoch:9000, train_accuracy: 0.990000\n","Epoch:9100, train_accuracy: 1.000000\n","Epoch:9200, train_accuracy: 0.990000\n","Epoch:9300, train_accuracy: 0.980000\n","Epoch:9400, train_accuracy: 1.000000\n","Epoch:9500, train_accuracy: 0.970000\n","Epoch:9600, train_accuracy: 1.000000\n","Epoch:9700, train_accuracy: 0.980000\n","Epoch:9800, train_accuracy: 0.990000\n","Epoch:9900, train_accuracy: 0.990000\n","test accuracy:0.992500\n"],"name":"stdout"}]}]}